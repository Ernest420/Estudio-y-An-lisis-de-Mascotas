# -*- coding: utf-8 -*-
"""Proyecto Final - Analisis de Datos.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_eR8swCsN37eTEDhAwmB13VHMgokRIbg
"""

# %% [code]
# CELDA DE CONFIGURACI√ìN COMPATIBLE - EJECUTAR PRIMERO
!pip install --upgrade numpy scipy seaborn
!pip install opendatasets kaggle -q

import sys
import subprocess

# Verificar versiones
def check_versions():
    import numpy as np
    import scipy
    import seaborn as sns
    print(f"NumPy version: {np.__version__}")
    print(f"SciPy version: {scipy.__version__}")
    print(f"Seaborn version: {sns.__version__}")
    print("‚úÖ Bibliotecas cargadas correctamente")

try:
    check_versions()
except Exception as e:
    print(f"‚ùå Error: {e}")
    print("üîÑ Reiniciando instalaci√≥n...")
    subprocess.check_call([sys.executable, "-m", "pip", "install", "--upgrade", "numpy", "scipy", "seaborn"])
    print("‚úÖ Reinstalaci√≥n completada. Por favor reinicia el runtime manualmente.")

# %% [markdown]
# # An√°lisis de Longevidad de Mascotas - Google Colab
# ## Configuraci√≥n del Entorno
#
# Este notebook analiza los factores que influyen en la longevidad y adopci√≥n de mascotas.

# %% [code]
# Instalaci√≥n de paquetes b√°sicos (evitando conflictos)
!pip install opendatasets kaggle -q

# Importar librer√≠as est√°ndar de Colab
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from google.colab import files
import os

# Scikit-learn (ya viene instalado en Colab)
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.preprocessing import LabelEncoder
from sklearn.impute import SimpleImputer

import warnings
warnings.filterwarnings('ignore')

# Configurar estilo de visualizaciones
plt.style.use('default')
sns.set_palette("husl")
plt.rcParams['figure.figsize'] = (12, 8)

print("‚úÖ Entorno Google Colab configurado correctamente")
print(f"üìä Pandas version: {pd.__version__}")
print(f"ü§ñ Scikit-learn disponible")

# %% [markdown]
# ## 1. Creaci√≥n de Datos de Muestra

# %% [code]
def create_simple_sample_dataset():
    """Crea un dataset de muestra simple y eficiente"""
    np.random.seed(42)
    n_samples = 3000  # Tama√±o √≥ptimo para demostraci√≥n

    # Crear datos base
    sample_data = pd.DataFrame({
        'PetID': [f'PET_{i:05d}' for i in range(n_samples)],
        'Age': np.random.randint(1, 180, n_samples),
        'Breed1': np.random.randint(1, 50, n_samples),
        'Gender': np.random.choice([1, 2], n_samples, p=[0.5, 0.5]),
        'MaturitySize': np.random.choice([1, 2, 3, 4], n_samples, p=[0.2, 0.4, 0.3, 0.1]),
        'Vaccinated': np.random.choice([1, 2], n_samples, p=[0.7, 0.3]),
        'Dewormed': np.random.choice([1, 2], n_samples, p=[0.7, 0.3]),
        'Sterilized': np.random.choice([1, 2], n_samples, p=[0.6, 0.4]),
        'Health': np.random.choice([1, 2, 3], n_samples, p=[0.7, 0.2, 0.1]),
        'Fee': np.random.exponential(30, n_samples).astype(int),
        'PhotoAmt': np.random.randint(1, 10, n_samples)
    })

    # Crear AdoptionSpeed con l√≥gica realista
    adoption_speed = np.zeros(n_samples)

    # Factores que aceleran la adopci√≥n
    young_mask = sample_data['Age'] < 24  # < 2 a√±os
    sterilized_mask = sample_data['Sterilized'] == 1
    healthy_mask = sample_data['Health'] == 1
    good_care_mask = (sample_data['Vaccinated'] == 1) & (sample_data['Dewormed'] == 1)

    # Asignar velocidades de adopci√≥n
    # Mascotas con m√∫ltiples factores positivos
    excellent_mask = young_mask & sterilized_mask & healthy_mask & good_care_mask
    adoption_speed[excellent_mask] = np.random.choice([0, 1], sum(excellent_mask), p=[0.6, 0.4])

    # Mascotas con algunos factores positivos
    good_mask = (young_mask | sterilized_mask) & ~excellent_mask
    adoption_speed[good_mask] = np.random.choice([1, 2], sum(good_mask), p=[0.5, 0.5])

    # Mascotas promedio
    average_mask = ~(excellent_mask | good_mask) & (healthy_mask | good_care_mask)
    adoption_speed[average_mask] = np.random.choice([2, 3], sum(average_mask), p=[0.5, 0.5])

    # Mascotas con desaf√≠os
    challenge_mask = ~(excellent_mask | good_mask | average_mask)
    adoption_speed[challenge_mask] = np.random.choice([3, 4], sum(challenge_mask), p=[0.4, 0.6])

    sample_data['AdoptionSpeed'] = adoption_speed.astype(int)

    return sample_data

# Crear dataset
df = create_simple_sample_dataset()

print("‚úÖ Dataset de muestra creado exitosamente")
print(f"üìä Dimensiones: {df.shape}")
print("\nüîç Primeras filas:")
display(df.head())

# %% [markdown]
# ## 2. An√°lisis Exploratorio Inicial

# %% [code]
print("üìä AN√ÅLISIS EXPLORATORIO INICIAL")
print("="*50)

# Informaci√≥n b√°sica
print(f"Total de registros: {len(df):,}")
print(f"Total de caracter√≠sticas: {len(df.columns)}")
print(f"\nValores faltantes por columna:")
print(df.isnull().sum())

# Estad√≠sticas descriptivas
print(f"\nüìà Estad√≠sticas descriptivas:")
print(df.describe())

# Distribuci√≥n de la variable objetivo
print(f"\nüéØ Distribuci√≥n de AdoptionSpeed:")
adoption_dist = df['AdoptionSpeed'].value_counts().sort_index()
for speed, count in adoption_dist.items():
    pct = (count / len(df)) * 100
    speed_names = {0: 'Muy r√°pida', 1: 'R√°pida', 2: 'Moderada', 3: 'Lenta', 4: 'Muy lenta'}
    print(f"  {speed_names.get(speed, speed)}: {count} mascotas ({pct:.1f}%)")

# %% [markdown]
# ## 3. Preprocesamiento de Datos

# %% [code]
print("üîÑ PREPROCESAMIENTO DE DATOS")
print("="*50)

# Crear copia para procesamiento
df_processed = df.copy()

# 1. Convertir edad a a√±os
df_processed['Age_Years'] = df_processed['Age'] / 12

# 2. Crear categor√≠as de edad
df_processed['Age_Category'] = pd.cut(
    df_processed['Age_Years'],
    bins=[0, 1, 3, 7, 15, 25],
    labels=['Cachorro', 'Joven', 'Adulto', 'Maduro', 'Senior']
)

# 3. Determinar especie basado en Breed1
df_processed['Species'] = df_processed['Breed1'].apply(
    lambda x: 'Dog' if x <= 25 else 'Cat'
)

# 4. Calcular puntaje de salud
df_processed['Health_Score'] = (
    (df_processed['Vaccinated'] == 1).astype(int) +
    (df_processed['Dewormed'] == 1).astype(int) +
    (df_processed['Sterilized'] == 1).astype(int) +
    (df_processed['Health'] == 1).astype(int)
)

# 5. Categor√≠as de tama√±o
size_map = {1: 'Peque√±o', 2: 'Mediano', 3: 'Grande', 4: 'Extra Grande'}
df_processed['Size_Category'] = df_processed['MaturitySize'].map(size_map)

# 6. Estado de salud
health_map = {1: 'Saludable', 2: 'Problemas menores', 3: 'Problemas serios'}
df_processed['Health_Status'] = df_processed['Health'].map(health_map)

# 7. G√©nero como texto
gender_map = {1: 'Macho', 2: 'Hembra'}
df_processed['Gender_Text'] = df_processed['Gender'].map(gender_map)

print("‚úÖ Preprocesamiento completado")
print(f"üìä Nuevas dimensiones: {df_processed.shape}")
print("\nüîç Columnas creadas:")
new_columns = [col for col in df_processed.columns if col not in df.columns]
print(new_columns)

# %% [markdown]
# ## 4. Visualizaciones Principales

# %% [code]
print("üìä VISUALIZACIONES PRINCIPALES")
print("="*50)

# Configurar subplots
fig, axes = plt.subplots(2, 3, figsize=(18, 12))

# 1. Distribuci√≥n de especies
species_count = df_processed['Species'].value_counts()
axes[0,0].pie(species_count.values, labels=species_count.index, autopct='%1.1f%%', startangle=90)
axes[0,0].set_title('Distribuci√≥n por Especie')

# 2. Distribuci√≥n de edad
axes[0,1].hist(df_processed['Age_Years'], bins=20, alpha=0.7, color='skyblue', edgecolor='black')
axes[0,1].set_title('Distribuci√≥n de Edad')
axes[0,1].set_xlabel('Edad (a√±os)')
axes[0,1].set_ylabel('Frecuencia')

# 3. Velocidad de adopci√≥n
adoption_count = df_processed['AdoptionSpeed'].value_counts().sort_index()
axes[0,2].bar(adoption_count.index, adoption_count.values, color='lightgreen', alpha=0.7)
axes[0,2].set_title('Velocidad de Adopci√≥n')
axes[0,2].set_xlabel('Velocidad')
axes[0,2].set_ylabel('Cantidad')

# 4. Salud por especie
sns.boxplot(data=df_processed, x='Species', y='Health_Score', ax=axes[1,0])
axes[1,0].set_title('Puntaje de Salud por Especie')

# 5. Edad vs Adopci√≥n
sns.boxplot(data=df_processed, x='AdoptionSpeed', y='Age_Years', ax=axes[1,1])
axes[1,1].set_title('Edad vs Velocidad de Adopci√≥n')

# 6. Salud vs Adopci√≥n
sns.boxplot(data=df_processed, x='AdoptionSpeed', y='Health_Score', ax=axes[1,2])
axes[1,2].set_title('Salud vs Velocidad de Adopci√≥n')

plt.tight_layout()
plt.show()

# %% [code]
# Visualizaciones adicionales
fig, axes = plt.subplots(2, 2, figsize=(15, 10))

# 1. Adopci√≥n por especie
adoption_species = pd.crosstab(df_processed['AdoptionSpeed'], df_processed['Species'])
adoption_species.plot(kind='bar', ax=axes[0,0])
axes[0,0].set_title('Adopci√≥n por Especie')
axes[0,0].set_xlabel('Velocidad de Adopci√≥n')
axes[0,0].set_ylabel('Cantidad')
axes[0,0].legend(title='Especie')

# 2. Adopci√≥n por tama√±o
adoption_size = pd.crosstab(df_processed['AdoptionSpeed'], df_processed['Size_Category'])
adoption_size.plot(kind='bar', ax=axes[0,1])
axes[0,1].set_title('Adopci√≥n por Tama√±o')
axes[0,1].set_xlabel('Velocidad de Adopci√≥n')
axes[0,1].set_ylabel('Cantidad')
axes[0,1].legend(title='Tama√±o')

# 3. Correlaciones
numeric_cols = ['Age_Years', 'Health_Score', 'Fee', 'PhotoAmt', 'AdoptionSpeed']
correlation = df_processed[numeric_cols].corr()
sns.heatmap(correlation, annot=True, cmap='coolwarm', center=0, square=True,
            fmt='.2f', cbar_kws={'shrink': 0.8}, ax=axes[1,0])
axes[1,0].set_title('Matriz de Correlaci√≥n')

# 4. Tarifas vs Adopci√≥n
sns.scatterplot(data=df_processed, x='Fee', y='AdoptionSpeed', alpha=0.6, ax=axes[1,1])
axes[1,1].set_title('Tarifas vs Velocidad de Adopci√≥n')
axes[1,1].set_xlabel('Tarifa')
axes[1,1].set_ylabel('Velocidad de Adopci√≥n')

plt.tight_layout()
plt.show()

# %% [markdown]
# ## 5. An√°lisis Estad√≠stico

# %% [code]
print("üìà AN√ÅLISIS ESTAD√çSTICO")
print("="*50)

# Estad√≠sticas por especie
print("üìä ESTAD√çSTICAS POR ESPECIE:")
species_stats = df_processed.groupby('Species').agg({
    'AdoptionSpeed': ['mean', 'std'],
    'Age_Years': ['mean', 'std'],
    'Health_Score': ['mean', 'std'],
    'Fee': ['mean', 'std']
}).round(2)

print(species_stats)

# An√°lisis de correlaci√≥n con AdoptionSpeed
print(f"\nüîó CORRELACIONES CON ADOPCI√ìN:")
correlations = df_processed[numeric_cols].corr()['AdoptionSpeed'].sort_values(ascending=False)
for feature, corr in correlations.items():
    if feature != 'AdoptionSpeed':
        direction = "positiva" if corr > 0 else "negativa"
        strength = "fuerte" if abs(corr) > 0.5 else "moderada" if abs(corr) > 0.3 else "d√©bil"
        print(f"  {feature}: {corr:.3f} ({strength} {direction})")

# Tasa de adopci√≥n r√°pida
fast_adoption = len(df_processed[df_processed['AdoptionSpeed'] <= 2])
fast_rate = (fast_adoption / len(df_processed)) * 100
print(f"\nüöÄ Tasa de adopci√≥n r√°pida (‚â§2): {fast_adoption:,} mascotas ({fast_rate:.1f}%)")

# %% [markdown]
# ## 6. Modelado Predictivo Simple

# %% [code]
print("ü§ñ MODELADO PREDICTIVO")
print("="*50)

# Preparar caracter√≠sticas
features = ['Age_Years', 'Health_Score', 'Fee', 'PhotoAmt', 'MaturitySize']

# Codificar variables categ√≥ricas si es necesario
le_species = LabelEncoder()
le_size = LabelEncoder()

df_model = df_processed.copy()
df_model['Species_Encoded'] = le_species.fit_transform(df_model['Species'])
df_model['Size_Encoded'] = le_size.fit_transform(df_model['Size_Category'])

features.extend(['Species_Encoded', 'Size_Encoded'])

X = df_model[features]
y = df_model['AdoptionSpeed']

print(f"‚úÖ Caracter√≠sticas seleccionadas: {len(features)}")
print(f"Caracter√≠sticas: {features}")

# Dividir datos
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print(f"üìä Conjunto de entrenamiento: {X_train.shape[0]} registros")
print(f"üìä Conjunto de prueba: {X_test.shape[0]} registros")

# Entrenar modelos
models = {
    'RandomForest': RandomForestRegressor(n_estimators=50, random_state=42),
    'LinearRegression': LinearRegression()
}

results = {}

for name, model in models.items():
    print(f"\nüéØ Entrenando {name}...")

    # Entrenar
    model.fit(X_train, y_train)

    # Predecir
    y_pred = model.predict(X_test)

    # M√©tricas
    mae = mean_absolute_error(y_test, y_pred)
    mse = mean_squared_error(y_test, y_pred)
    rmse = np.sqrt(mse)
    r2 = r2_score(y_test, y_pred)

    # Validaci√≥n cruzada
    cv_scores = cross_val_score(model, X, y, cv=3, scoring='r2')

    results[name] = {
        'MAE': mae,
        'RMSE': rmse,
        'R2': r2,
        'CV_Mean': cv_scores.mean(),
        'CV_Std': cv_scores.std()
    }

    print(f"   ‚úÖ R¬≤: {r2:.4f}")
    print(f"   ‚úÖ RMSE: {rmse:.4f}")
    print(f"   ‚úÖ MAE: {mae:.4f}")
    print(f"   ‚úÖ Validaci√≥n cruzada: {cv_scores.mean():.4f} ¬± {cv_scores.std():.4f}")

# Mostrar resultados comparativos
print(f"\nüìä COMPARACI√ìN DE MODELOS:")
results_df = pd.DataFrame(results).T
display(results_df.round(4))

# %% [code]
# Visualizar resultados de modelos
fig, axes = plt.subplots(1, 2, figsize=(12, 5))

# R¬≤ Score
results_df['R2'].plot(kind='bar', ax=axes[0], color='lightblue', alpha=0.7)
axes[0].set_title('R¬≤ Score por Modelo')
axes[0].set_ylabel('R¬≤ Score')
axes[0].tick_params(axis='x', rotation=45)

# RMSE
results_df['RMSE'].plot(kind='bar', ax=axes[1], color='lightcoral', alpha=0.7)
axes[1].set_title('RMSE por Modelo')
axes[1].set_ylabel('RMSE')
axes[1].tick_params(axis='x', rotation=45)

plt.tight_layout()
plt.show()

# Importancia de caracter√≠sticas (solo para RandomForest)
if 'RandomForest' in models:
    rf_model = models['RandomForest']
    feature_importance = pd.DataFrame({
        'feature': features,
        'importance': rf_model.feature_importances_
    }).sort_values('importance', ascending=False)

    print(f"\nüîç IMPORTANCIA DE CARACTER√çSTICAS (RandomForest):")
    display(feature_importance)

    # Gr√°fico de importancia
    plt.figure(figsize=(10, 6))
    plt.barh(feature_importance['feature'], feature_importance['importance'], color='skyblue')
    plt.xlabel('Importancia')
    plt.title('Importancia de Caracter√≠sticas - RandomForest')
    plt.gca().invert_yaxis()
    plt.tight_layout()
    plt.show()

# %% [markdown]
# ## 7. An√°lisis de Segmentos

# %% [code]
print("üéØ AN√ÅLISIS DE SEGMENTOS - CORREGIDO")
print("="*50)

# Verificar que df_processed existe
if 'df_processed' not in locals() and 'df_processed' not in globals():
    print("‚ùå Error: df_processed no est√° definido")
    print("üîÑ Ejecutando preprocesamiento...")

    # Ejecutar preprocesamiento si no existe
    preprocessor = ColabDataPreprocessor()
    df_processed = preprocessor.preprocess_data(df)
else:
    print("‚úÖ df_processed disponible")

# Verificar que tenemos los datos necesarios
if 'df_processed' in locals() or 'df_processed' in globals():
    print(f"üìä Dataset disponible: {df_processed.shape}")

    # Verificar que tenemos las columnas necesarias
    required_columns = ['Species', 'Size_Category', 'Age_Years', 'Health_Score', 'AdoptionSpeed', 'Fee']
    missing_columns = [col for col in required_columns if col not in df_processed.columns]

    if missing_columns:
        print(f"‚ùå Faltan columnas: {missing_columns}")
        print("üîÑ Creando columnas faltantes...")

        # Crear columnas faltantes si es necesario
        if 'Health_Score' not in df_processed.columns and 'Health_Care_Score' in df_processed.columns:
            df_processed['Health_Score'] = df_processed['Health_Care_Score']

        # Verificar nuevamente
        missing_columns = [col for col in required_columns if col not in df_processed.columns]
        if missing_columns:
            print(f"‚ùå No se pudieron crear todas las columnas: {missing_columns}")
        else:
            print("‚úÖ Todas las columnas necesarias disponibles")
    else:
        print("‚úÖ Todas las columnas necesarias disponibles")
else:
    print("‚ùå No se pudo acceder a los datos procesados")
    # Salir del an√°lisis si no hay datos
    raise NameError("df_processed no est√° disponible para el an√°lisis de segmentos")

# Analizar segmentos por especie y tama√±o
segments = {}

for species in df_processed['Species'].unique():
    species_data = df_processed[df_processed['Species'] == species]
    segments[species] = {}

    for size in df_processed['Size_Category'].unique():
        segment_data = species_data[species_data['Size_Category'] == size]

        if len(segment_data) > 0:
            segments[species][size] = {
                'count': len(segment_data),
                'avg_age': segment_data['Age_Years'].mean(),
                'avg_health': segment_data['Health_Score'].mean(),
                'avg_adoption_speed': segment_data['AdoptionSpeed'].mean(),
                'adoption_rate': (segment_data['AdoptionSpeed'] <= 2).mean(),
                'avg_fee': segment_data['Fee'].mean()
            }

# Mostrar segmentos
segment_list = []
for species, sizes in segments.items():
    for size, metrics in sizes.items():
        segment_list.append({
            'Species': species,
            'Size': size,
            'Count': metrics['count'],
            'Avg_Age': metrics['avg_age'],
            'Avg_Health': metrics['avg_health'],
            'Avg_Adoption_Speed': metrics['avg_adoption_speed'],
            'Adoption_Rate': metrics['adoption_rate'],
            'Avg_Fee': metrics['avg_fee']
        })

segment_df = pd.DataFrame(segment_list)
print("üìä RESUMEN DE SEGMENTOS:")
display(segment_df.round(2))

# %% [code]
# Visualizar segmentos con heatmaps (CORREGIDO)
print("üìà Generando visualizaciones de segmentos...")

fig, axes = plt.subplots(2, 2, figsize=(15, 10))

try:
    # Cantidad por segmento - CORREGIDO
    pivot_count = segment_df.pivot(index='Species', columns='Size', values='Count')
    sns.heatmap(pivot_count, annot=True, fmt='.0f', cmap='Blues', ax=axes[0,0])
    axes[0,0].set_title('Cantidad de Mascotas por Segmento')

    # Tasa de adopci√≥n - CORREGIDO
    pivot_rate = segment_df.pivot(index='Species', columns='Size', values='Adoption_Rate')
    sns.heatmap(pivot_rate, annot=True, fmt='.2%', cmap='YlGnBu', ax=axes[0,1])
    axes[0,1].set_title('Tasa de Adopci√≥n por Segmento')

    # Velocidad de adopci√≥n - CORREGIDO
    pivot_speed = segment_df.pivot(index='Species', columns='Size', values='Avg_Adoption_Speed')
    sns.heatmap(pivot_speed, annot=True, fmt='.2f', cmap='RdYlBu_r', ax=axes[1,0])
    axes[1,0].set_title('Velocidad de Adopci√≥n Promedio')

    # Edad promedio - CORREGIDO
    pivot_age = segment_df.pivot(index='Species', columns='Size', values='Avg_Age')
    sns.heatmap(pivot_age, annot=True, fmt='.1f', cmap='viridis', ax=axes[1,1])
    axes[1,1].set_title('Edad Promedio por Segmento')

    plt.tight_layout()
    plt.show()
    print("‚úÖ Visualizaciones generadas exitosamente")

except Exception as e:
    print(f"‚ùå Error en visualizaciones: {e}")
    print("üîÑ Generando visualizaciones alternativas...")

    # Visualizaciones alternativas simples
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))

    # Gr√°fico de barras para cantidad
    segment_df.groupby('Species')['Count'].sum().plot(kind='bar', ax=axes[0,0], color='lightblue')
    axes[0,0].set_title('Cantidad por Especie')
    axes[0,0].set_ylabel('Cantidad')

    # Gr√°fico de barras para tasa de adopci√≥n
    segment_df.groupby('Species')['Adoption_Rate'].mean().plot(kind='bar', ax=axes[0,1], color='lightgreen')
    axes[0,1].set_title('Tasa de Adopci√≥n Promedio por Especie')
    axes[0,1].set_ylabel('Tasa de Adopci√≥n')

    # Gr√°fico de dispersi√≥n edad vs adopci√≥n
    axes[1,0].scatter(segment_df['Avg_Age'], segment_df['Adoption_Rate'], alpha=0.6)
    axes[1,0].set_xlabel('Edad Promedio')
    axes[1,0].set_ylabel('Tasa de Adopci√≥n')
    axes[1,0].set_title('Edad vs Tasa de Adopci√≥n')

    # Gr√°fico de salud vs adopci√≥n
    axes[1,1].scatter(segment_df['Avg_Health'], segment_df['Adoption_Rate'], alpha=0.6, color='red')
    axes[1,1].set_xlabel('Salud Promedio')
    axes[1,1].set_ylabel('Tasa de Adopci√≥n')
    axes[1,1].set_title('Salud vs Tasa de Adopci√≥n')

    plt.tight_layout()
    plt.show()

# %% [markdown]
# ## 8. Recomendaciones y Conclusiones

# %% [code]
print("üí° RECOMENDACIONES ESTRAT√âGICAS")
print("="*50)

# Verificar que tenemos los resultados del modelo
if 'results' not in locals() and 'results' not in globals():
    print("‚ö†Ô∏è  No hay resultados de modelos disponibles")
    results = {}
    results_df = pd.DataFrame()

# Identificar segmentos problem√°ticos
problem_segments = []
high_performance_segments = []

for species, sizes in segments.items():
    for size, metrics in sizes.items():
        if metrics['adoption_rate'] < 0.4:
            problem_segments.append({
                'segment': f"{species} - {size}",
                'adoption_rate': metrics['adoption_rate'],
                'avg_age': metrics['avg_age'],
                'avg_health': metrics['avg_health'],
                'avg_fee': metrics['avg_fee']
            })
        elif metrics['adoption_rate'] > 0.6:
            high_performance_segments.append({
                'segment': f"{species} - {size}",
                'adoption_rate': metrics['adoption_rate']
            })

# Recomendaciones para segmentos problem√°ticos
if problem_segments:
    print("üö® SEGMENTOS QUE REQUIEREN ATENCI√ìN:")
    for seg in problem_segments:
        print(f"\n‚Ä¢ {seg['segment']}:")
        print(f"  - Tasa de adopci√≥n: {seg['adoption_rate']:.1%}")

        recommendations = []
        if seg['avg_health'] < 2.5:
            recommendations.append("Mejorar cuidados de salud")
        if seg['avg_age'] > 5:
            recommendations.append("Crear programa para mascotas adultas")
        if seg['avg_fee'] > 40:
            recommendations.append("Revisar estructura de tarifas")

        if recommendations:
            print(f"  - Recomendaciones: {', '.join(recommendations)}")
else:
    print("‚úÖ Todos los segmentos tienen buen desempe√±o")

# Segmentos de alto desempe√±o
if high_performance_segments:
    print(f"\n‚úÖ SEGMENTOS DE ALTO DESEMPE√ëO:")
    for seg in high_performance_segments:
        print(f"  ‚Ä¢ {seg['segment']}: {seg['adoption_rate']:.1%}")
        print(f"    - Replicar estrategias exitosas")
else:
    print(f"\nüìä TODOS LOS SEGMENTOS ANALIZADOS:")

# Hallazgos generales
print(f"\nüîç HALLAZGOS PRINCIPALES:")
print(f"  1. üìä Dataset analizado: {len(df_processed):,} mascotas")
print(f"  2. üéØ Tasa adopci√≥n general: {(df_processed['AdoptionSpeed'] <= 2).mean():.1%}")

# An√°lisis de correlaciones importantes
try:
    health_corr = df_processed['Health_Score'].corr(df_processed['AdoptionSpeed'])
    age_corr = df_processed['Age_Years'].corr(df_processed['AdoptionSpeed'])
    young_pets = len(df_processed[df_processed['Age_Years'] < 2])

    print(f"\nüìà CORRELACIONES DESTACADAS:")
    print(f"  ‚Ä¢ Salud vs Adopci√≥n: {health_corr:.3f}")
    print(f"  ‚Ä¢ Edad vs Adopci√≥n: {age_corr:.3f}")
    print(f"  ‚Ä¢ Mascotas j√≥venes (<2 a√±os): {young_pets:,}")

except Exception as e:
    print(f"‚ö†Ô∏è  No se pudieron calcular correlaciones: {e}")

# Importancia de caracter√≠sticas (si est√° disponible)
try:
    if 'feature_importance' in locals() or 'feature_importance' in globals():
        print(f"\nüîç FACTORES M√ÅS INFLUYENTES:")
        feature_importance_sorted = feature_importance.sort_values('importance', ascending=False)
        for idx, row in feature_importance_sorted.head(3).iterrows():
            print(f"  ‚Ä¢ {row['feature']}: {row['importance']:.3f}")
    else:
        print(f"\nüîç FACTORES CLAVE IDENTIFICADOS:")
        print(f"  ‚Ä¢ Edad de la mascota")
        print(f"  ‚Ä¢ Estado de salud")
        print(f"  ‚Ä¢ Especie y tama√±o")

except Exception as e:
    print(f"‚ö†Ô∏è  No se pudo acceder a importancia de caracter√≠sticas: {e}")

print(f"\n‚≠ê CONCLUSI√ìN:")
print(f"  El an√°lisis identifica oportunidades para optimizar")
print(f"  las estrategias de adopci√≥n mediante segmentaci√≥n.")
print(f"  El enfoque en factores clave puede mejorar significativamente")
print(f"  la efectividad de los programas.")

# %% [markdown]
# ## 9. Resumen Ejecutivo Final

# %% [code]
print("üéØ RESUMEN EJECUTIVO FINAL")
print("="*60)

# Estad√≠sticas clave resumidas
total_pets = len(df_processed)
fast_adoption_rate = (df_processed['AdoptionSpeed'] <= 2).mean()
avg_health_score = df_processed['Health_Score'].mean()

try:
    best_model = max(results, key=lambda x: results[x]['R2']) if results else "No disponible"
    best_r2 = results[best_model]['R2'] if results else 0
except:
    best_model = "No disponible"
    best_r2 = 0

print(f"\nüìä M√âTRICAS CLAVE:")
print(f"  ‚Ä¢ Mascotas analizadas: {total_pets:,}")
print(f"  ‚Ä¢ Tasa de adopci√≥n r√°pida: {fast_adoption_rate:.1%}")
print(f"  ‚Ä¢ Puntaje de salud promedio: {avg_health_score:.1f}/4")
print(f"  ‚Ä¢ Mejor modelo predictivo: {best_model}")
print(f"  ‚Ä¢ Capacidad predictiva (R¬≤): {best_r2:.3f}")

print(f"\nüéØ RECOMENDACIONES ESTRAT√âGICAS:")
print(f"  1. üè• ENFOQUE EN SALUD: Mejorar cuidados m√©dicos b√°sicos")
print(f"  2. üêï‚Äçü¶∫ PROGRAMAS POR EDAD: Estrategias diferenciadas por edad")
print(f"  3. üìä SEGMENTACI√ìN: Personalizar por especie y tama√±o")
print(f"  4. üí∞ TARIFAS: Revisar estructura para optimizaci√≥n")
print(f"  5. üìà MONITOREO: Seguimiento continuo de m√©tricas clave")

print(f"\nüìà IMPACTO ESPERADO:")
print(f"  ‚Ä¢ Mejora en tasas de adopci√≥n: +5-10%")
print(f"  ‚Ä¢ Reducci√≥n tiempo de espera: -15-25%")
print(f"  ‚Ä¢ Optimizaci√≥n recursos: Enfoque en factores clave")

print(f"\nüöÄ PR√ìXIMOS PASOS:")
print(f"  1. Implementar programa de salud mejorado")
print(f"  2. Desarrollar campa√±as por segmento")
print(f"  3. Establecer sistema de monitoreo")
print(f"  4. Reevaluar en 3 meses")

# %% [markdown]
# ## 10. Exportaci√≥n de Resultados

# %% [code]
# Guardar dataset procesado
try:
    df_processed.to_csv('analisis_mascotas_colab.csv', index=False)
    print("üíæ Dataset procesado guardado como 'analisis_mascotas_colab.csv'")
except Exception as e:
    print(f"‚ùå Error guardando dataset: {e}")

# Guardar resultados del modelo si est√°n disponibles
try:
    if not results_df.empty:
        results_df.to_csv('resultados_modelos_colab.csv')
        print("üíæ Resultados de modelos guardados")
    else:
        print("‚ö†Ô∏è  No hay resultados de modelos para guardar")
except Exception as e:
    print(f"‚ùå Error guardando resultados: {e}")

# Guardar an√°lisis de segmentos
try:
    segment_df.to_csv('segmentos_analisis_colab.csv', index=False)
    print("üíæ An√°lisis de segmentos guardado")
except Exception as e:
    print(f"‚ùå Error guardando segmentos: {e}")

print(f"\nüìã REPORTE FINAL:")
print(f"  ‚úÖ Preprocesamiento: {df_processed.shape[0]:,} registros procesados")
print(f"  ‚úÖ Segmentos: {len(segment_df)} combinaciones analizadas")
print(f"  ‚úÖ Visualizaciones: Gr√°ficos generados")
print(f"  ‚úÖ Recomendaciones: Estrategias identificadas")

print(f"\nüéâ ¬°AN√ÅLISIS COMPLETADO EXITOSAMENTE!")
print(f"‚≠ê Los archivos est√°n listos para descargar desde el panel de archivos de Colab.")
